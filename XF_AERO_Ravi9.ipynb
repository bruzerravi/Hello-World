{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bruzerravi/Hello-World/blob/master/XF_AERO_Ravi9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8wFChjVUvsl_"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python\n",
        "# coding: utf-8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLDJbViXvsmB"
      },
      "source": [
        "In[73]:<br>\n",
        "Last successful run to completion on May 21, 2022<br>\n",
        "This code works only for NACA 4 digit airfoils and output generated by Xflr5    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_ceXNgHvsmC"
      },
      "source": [
        "Ravi9 is developed from Ravi8 to have Cp (99 values)  Re, Alfa, camber, camber_xmax, thickness and turb parameters<br>\n",
        "(together named as fv) as input and airfoil y-coordinates as output.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-2utnMCvsmC"
      },
      "source": [
        "This code is developed from Ravi8 version <br>\n",
        "The code reads an output file created by XF_AERO_DataRead9 which looks like <br>\n",
        "DataSets\\\\Cp_Graph_nacaxxxx_Alfa-m6-10-1_Re-10-100-10_thk-2-12-2_turb_yp_out.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgHEJvhSvsmD"
      },
      "source": [
        "The code XF_AERO_DataRead9 takes as its input the (xflr5 created)<br>\n",
        "\"DataSets\\\\Cp_Graph_nacaxxxx_Alfa-m6-10-1_Re-10-100-10_thk-2-12-2.csv\" file and outputs  <br>\n",
        "\"DataSets\\\\Cp_Graph_nacaxxxx_Alfa-m6-10-1_Re-10-100-10_thk-2-12-2_turb_yp_out.csv\"<br>\n",
        "which is the input file for this code Ravi9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kk1DZ8LGvsmD"
      },
      "source": [
        "The training set is now in the proper XY form but is read as a dataframe<br>\n",
        "which must be processed to recreate the XY data for the ANN model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxLeEWMFvsmD"
      },
      "source": [
        "This version of the code checks for consistency of the training set data <br>\n",
        "read from the input file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F8zs6H7NvsmE"
      },
      "outputs": [],
      "source": [
        " \n",
        "# This version is still incomplete: The save model option implemented here does not work\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COiFSuYIvsmE"
      },
      "source": [
        "The XY dataset created from the input dataset after random shuffling is written to a .csv file<br>\n",
        "<br>\n",
        "The only input files are the *_out.csv and Profiles_nacaxxxx.csv <br>\n",
        "These are the only two inputs to run this code All other parameters are detrmined from these inputs<br>\n",
        "The number of training and test examples may be input as seen below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0bqNJo-qvsmF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import datetime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8EgJv_NFvsmF"
      },
      "source": [
        "mport tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_S7sip5mvsmF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ET04SNvTvsmG"
      },
      "outputs": [],
      "source": [
        "localtime = time.asctime( time.localtime(time.time()) )\n",
        "print (\"\\n \\n ***********************************Local start time :\", localtime, \"***********************************\")\n",
        "print (\"\\n \\n ******************************************** Executing XF_AERO_Ravi9 ********************************************\")\n",
        "print (\"\\n \\n *********************  Input data for this code is generated by executing XF_AERO_DataRead9 *********************\")\n",
        "print (\"\\n \\n **** XF_AERO_Ravi9 predicts profile coordinates for test cases given Cp distribution on Airfoil and the flow parameters***\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcGHRZ1rvsmH"
      },
      "source": [
        "---------------------------------------------------------------------------<br>\n",
        "File names defined"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eH8_0Ff2vsmH"
      },
      "outputs": [],
      "source": [
        "data_file_in_fv = '/content/drive/MyDrive/DataSets/Cp_Graph_naca44xx_Alfa-m6-10-1_Re-10-100-10_thk-2-12-2_turb_yp_out.csv'\n",
        "data_file_af_case = data_file_in_fv[18:len(data_file_in_fv)-8]\n",
        "data_file_out_yp = data_file_af_case +\"_out.xlsx\"\n",
        "data_file_in_Pr = '/content/drive/MyDrive/DataSets/Profiles_naca44xx.csv'\n",
        "!ls /content/drive/MyDrive/DataSets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LgQeHoZfvsmH"
      },
      "outputs": [],
      "source": [
        "AF_family_name = data_file_in_fv[41:49]\n",
        "n_test = 40\n",
        "n_train = 50\n",
        "n_beg = 21          # The training example serial number to start extracting from\n",
        "n_end = n_beg + n_train\n",
        "print (\"\\n \\n ** The Input data file for this run is\",data_file_in_fv, \"**\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asy6eqFwvsmH"
      },
      "source": [
        "----------------------------------------------------------------------------<br>\n",
        "The calling function is<br>\n",
        "print_results(predictions, YY, X_trng_par_list, X_trng_af, Cp_trng_set, File_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfnGXW7xvsmI"
      },
      "source": [
        "Consolidate the reults matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLKtzwSvvsmJ"
      },
      "source": [
        "Write the results Dataset to an .xlsx file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0tnpPTbUvsmI"
      },
      "outputs": [],
      "source": [
        "def print_results(predictions, YY, X_par_list, X_af, Cp_set, file_name):\n",
        "    \n",
        "    np.set_printoptions(precision=3)\n",
        "    \n",
        "    file_name = \"Ravi9_\" + file_name    \n",
        "    results = np.zeros((1,YY.shape[1]))\n",
        "    results[0,:] = Cp_set[0,:]\n",
        "    results = np.concatenate((results, YY), axis=0)\n",
        "    results = np.concatenate((results, predictions), axis=0)\n",
        "    results = np.concatenate((results, Cp_set[1:,:]), axis=0)    \n",
        "    length_Xaf = len(X_af)\n",
        "# Collect Alfa, Re, thk results in an array to be written out in a file\n",
        "    length_Xpar = int(len(X_par_list)/2)         #divide by 2 because the length of X_par_list is double of X_af\n",
        "    row_labels = []\n",
        "    row_labels.append('x_p')\n",
        "    index = np.arange(0,len(X_par_list),1)\n",
        "    for i in index:\n",
        "        stringi = X_par_list[i]\n",
        "        row_labels.append(X_par_list[i])\n",
        "   \n",
        "    \n",
        "    index = np.arange(1,length_Xaf+1,1)\n",
        "    for i in index:\n",
        "        string_af = X_af[i-1]\n",
        "        row_labels[i] = string_af + '-' + row_labels[i]\n",
        "    index = np.arange(1,length_Xaf+1,1)\n",
        "    for i in index:\n",
        "        string_af = X_af[i-1]\n",
        "        row_labels[length_Xaf+i] = string_af + row_labels[length_Xaf+i]\n",
        "    len(row_labels)\n",
        "    index = np.arange(0,length_Xpar,1)\n",
        "    for i in index:\n",
        "        stringi = X_par_list[i]\n",
        "        string1 = stringi[0:61] + 'Cp' + stringi[63:]\n",
        "        row_labels.append(string1)\n",
        "    index = np.arange(1,length_Xaf+1,1)\n",
        "    for i in index:\n",
        "        string_af = X_af[i-1]\n",
        "        row_labels[2*length_Xpar+i] = string_af + row_labels[2*length_Xpar+i]\n",
        "    df_results = pd.DataFrame(data=results, index=row_labels)\n",
        "    df_results.to_excel(file_name)\n",
        "    return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEdEInYnvsmJ"
      },
      "source": [
        "----------------------------------------------------------------------------<br>\n",
        "Calling function and arguments<br>\n",
        "plot_results(predictions, YY, X_test_par_list, X_test_af, Cp_test_set)\n",
        "Function definition to plot results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBrckprWvsmJ"
      },
      "source": [
        "Function definition to plot results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gR1S8RxovsmJ"
      },
      "source": [
        "Consolidate the results matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4vfkHLyvsmK"
      },
      "source": [
        "Create a dataframe of the results that can be plotted as graphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "96wg9-0wvsmJ"
      },
      "outputs": [],
      "source": [
        "def plot_results(Y_p, Y_a, X_par_list, X_af, Cp_set):\n",
        "    \n",
        "    length_Xaf = len(X_af)\n",
        "    Y_size = Y_p.shape\n",
        "    results = np.zeros((1,Y_a.shape[1]))\n",
        "    results[0,:] = Cp_set[0,:]                                  # sets the x-coordinates\n",
        "    results = np.concatenate((results, Cp_set[1:,:]), axis=0)   # the Cp distribution of the profile    \n",
        "    results = np.concatenate((results, Y_a), axis=0)            # Actual yp distribution\n",
        "    results = np.concatenate((results, Y_p), axis=0)            # predicted yp distribution\n",
        "    df_results = pd.DataFrame(data=results)\n",
        "    yp_err = np.zeros((1,Y_size[1]))\n",
        "    i_count = 0                         # count of number of test airfoils\n",
        "    while (i_count <= Y_size[0]-1):\n",
        "        row_labels = [\"Airfoil Profile\", \"yp_Actual\", \"yp_pred\", \"yp_err\"]\n",
        "        yp_err = np.array(df_results.iloc[Y_size[0] + i_count+1, :]-df_results.iloc[2*Y_size[0] + i_count+1, :])\n",
        "        Title1 = X_par_list[i_count]\n",
        "        Title2 = X_af[i_count] + \"_\" + Title1[0:53] + Title1[64:]\n",
        "        plt.figure(figsize=(15,7))\n",
        "        plt.plot(df_results.iloc[0, :], df_results.iloc[i_count+1, :])\n",
        "        plt.plot(df_results.iloc[0, :], df_results.iloc[Y_size[0] + i_count+1, :], marker='+')\n",
        "        plt.plot(df_results.iloc[0, :], df_results.iloc[2*Y_size[0] + i_count+1, :], marker='*')\n",
        "        plt.plot(df_results.iloc[0, :], yp_err[:], marker = 'o')\n",
        "        tit = Title2 + \" : Airfoil Cp Distribution and Profile\" \n",
        "        plt.title(tit)\n",
        "        plt.xlabel('x')\n",
        "        plt.ylabel('y, Cp')\n",
        "        plt.legend(row_labels, loc=1, prop={'size': 8})\n",
        "        i_count += 1\n",
        "    \n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cbXN6wWjvsmK"
      },
      "outputs": [],
      "source": [
        "def string_list_from_X_par(X_par_list):\n",
        "# Generate string list from X_par_list\n",
        "# Merge all entries in array column to a string\n",
        "    jrange = X_par_list.shape[1]\n",
        "    irange = X_par_list.shape[0]\n",
        "    si = []\n",
        "    i=0\n",
        "    while (i<= irange-1):\n",
        "        j=0\n",
        "        sj = \" \"\n",
        "        while (j<= jrange-1):\n",
        "            if j< jrange-1:\n",
        "                sj =  sj  + str(X_par_list[i,j]) + \" , \"\n",
        "            else:\n",
        "                sj =  sj  + str(X_par_list[i,j])\n",
        "            j = j+1\n",
        "        si.append(sj)\n",
        "        i = i+1\n",
        "    \n",
        "    i=0\n",
        "    while (i<= irange-1):\n",
        "        si[i] = \"(Alfa , Re, cmbr, cmbrx, thk,  NCrit, XTrTop, XtrBot)-actual-yp =\" + si[i]\n",
        "        i +=1\n",
        "    \n",
        "    i = irange\n",
        "    k=0\n",
        "    while (i<= 2*irange-1):\n",
        "        string = si[k]\n",
        "        sj = \"(Alfa , Re, cmbr, cmbrx, thk, NCrit, XTrTop, XtrBot)-pred-yp =\" + string[65:]\n",
        "        si.append(sj)\n",
        "        i +=1\n",
        "        k +=1\n",
        "    return si"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vr-vbTADvsmK"
      },
      "source": [
        "Read the input data frame consisting of the training set<br>\n",
        "Read the input data frame consisting of the training set<br>\n",
        "Note that each row of the input dataframe has n_Cp_var (=99) values followed by <br>\n",
        "n_par_var (=8) parameter variables and then n_yp_var (=99=n_yp_var) coordinate values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d63a043FvsmK"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(data_file_in_fv)\n",
        "df = df.sample(frac=1)\n",
        "df_Pr = pd.read_csv(data_file_in_Pr)\n",
        "af_trng_set = []\n",
        "af_trng_set = list(df.iloc[:,0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9N-omv0gvsmL"
      },
      "source": [
        "delete the first column from the dataframe read since that is only the row serial #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pf2Un3j6vsmL"
      },
      "outputs": [],
      "source": [
        "df = df.iloc[:,1:]\n",
        "df_size = df.shape\n",
        "af_family = data_file_af_case[0:8] \n",
        "dfPr_size = df_Pr.shape\n",
        "n_Cp_var=dfPr_size[0]\n",
        "n_yp_var = n_Cp_var"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2dcNE1svsmL"
      },
      "source": [
        "save the x-y set for each profile.  Note that the x-coordinate is same for all profiles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UrY3MnoWvsmL"
      },
      "outputs": [],
      "source": [
        "n_profiles = int(dfPr_size[1]/2)\n",
        "x_y_prof_coords = np.zeros((n_yp_var, n_profiles+1))\n",
        "x_y_prof_coords[:,0:2] = df_Pr.iloc[:,0:2]\n",
        "i = 3\n",
        "j = 2\n",
        "while (i <= 2*n_profiles-1):\n",
        "    x_y_prof_coords[:,j] = df_Pr.iloc[:,i]\n",
        "    i +=2\n",
        "    j +=1\n",
        "x_y_prof_coords = np.transpose(x_y_prof_coords)\n",
        "x_coord = np.zeros((1,n_yp_var))\n",
        "x_coord[0,:] = x_y_prof_coords[0,:]\n",
        "n_out_var = n_yp_var\n",
        "n_in_var = df_size[1] - n_out_var\n",
        "n_par_var = n_in_var - n_Cp_var"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7wPsmnavsmM"
      },
      "source": [
        "denote feature variable by fv_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ctW7AIJtvsmM"
      },
      "outputs": [],
      "source": [
        "fv_last = n_in_var-1        # Note that this is the column index of last fv value in any row\n",
        "col_last = df_size[1]-1     # Note that this is the column index of last value in any row\n",
        "print('\\n', \"          Feature variables are the upper and lower surface fv data, Alfa , Re, thk,  NCrit, XTrTop, XtrBot\")\n",
        "print(\"           size of Training Set is \", df_size[0], '\\n')\n",
        "print(\"           length of dataframe is \", df_size[1], '\\n')\n",
        "print(\"           size of fv_data is \", df_size[1]-n_out_var, '\\n')\n",
        "print(\"           the fv value in row #0 col #0 is  df.iloc[0,0] =\", df.iloc[0,0], '\\n')\n",
        "print(\"           the last fv value in row #0 col #last is  df.iloc[0,last] =\", df.iloc[0,fv_last], '\\n')\n",
        "print(\"           the last non-zero element on df.iloc[0,df_size[1]-1] =\", df.iloc[0,col_last], '\\n')\n",
        "fv_data = np.array(df.iloc[:,0:fv_last+1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4c2whuDQvsmM"
      },
      "source": [
        "Store the parameter array for later use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r236p2ZqvsmM"
      },
      "outputs": [],
      "source": [
        "X_par =  np.array(df.iloc[:,n_Cp_var:fv_last+1])\n",
        "print('\\n', \"           number of sets of fv_data is \", len(fv_data), '\\n')\n",
        "print(\"           the last fv value in row #0 col #last is  fv_data[0,last] =\", fv_data[0,fv_last], '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3e6hPgYvsmN"
      },
      "source": [
        "----------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZkzGl6pvsmN"
      },
      "source": [
        "reate X data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IGqAy3tvsmN"
      },
      "source": [
        "reating Y data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vw7O7kA5vsmN"
      },
      "outputs": [],
      "source": [
        "X = fv_data\n",
        "n_fv_data = X.shape[1]\n",
        "Y = []\n",
        "Y = df.iloc[:,fv_last+1:]\n",
        "print(\"  \\n \\n    the last non-zero element on Y.iloc[0,row_last] =\", Y.iloc[0,n_out_var-1], '\\n')\n",
        "Y = np.array(Y)\n",
        "Y = Y.astype(float)\n",
        "print(\"Last values in Y of row #0 \\n \\n y-coordinates \\n \\n\", Y[0, 0:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vzmo_GF3vsmN"
      },
      "source": [
        "Create XY set and shuffle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j1N-Z1N3vsmO"
      },
      "outputs": [],
      "source": [
        "rows = X.shape[0]\n",
        "cols = X.shape[1]\n",
        "print('\\n', \"           rows =\", rows, \"cols =\", cols, '\\n')\n",
        "assert fv_data.shape[0]==Y.shape[0], \"# of fv sets equals # of test Labels\"\n",
        "XY_set = np.zeros((rows,cols))\n",
        "print(\" \\n  XY set initialized       \\n\", XY_set.shape)\n",
        "XY_set = X\n",
        "print(\"    \\n XY set only feature variables \\n      \", XY_set.shape)\n",
        "XY_set = np.hstack((XY_set, Y))\n",
        "print(\"   \\n XY set Feature and Output variable \\n  \\n     \", XY_set.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0ZKaDo8vsmO"
      },
      "source": [
        "Shuffle the training set<br>\n",
        "p.random.shuffle(XY_set)<br>\n",
        "rint(\"\\n     XY_set after random shuffle  \\n \", XY_set.shape, '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjEnv7P1vsmO"
      },
      "source": [
        "ake the n_last  examples as the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0sh1V_d5vsmO"
      },
      "outputs": [],
      "source": [
        "X_test = np.zeros((n_test,cols))\n",
        "Y_test = np.zeros((n_test,cols))\n",
        "Cp_test = np.zeros((n_test,cols))\n",
        "n_last = n_test\n",
        "X_test = XY_set[XY_set.shape[0]-1-n_last:XY_set.shape[0]-1,:cols]\n",
        "Y_test = XY_set[XY_set.shape[0]-1-n_last:XY_set.shape[0]-1,cols:]\n",
        "assert X_test.shape[0]==Y_test.shape[0], \"# of test exampless equals # of test Labels\"\n",
        "Cp_test = XY_set[XY_set.shape[0]-1-n_last:XY_set.shape[0]-1,0:n_Cp_var]\n",
        "Cp_test_set = np.concatenate((x_coord, Cp_test), axis=0)\n",
        "X_test_par = XY_set[XY_set.shape[0]-1-n_last:XY_set.shape[0]-1,n_Cp_var:fv_last+1]\n",
        "X_test_af = af_trng_set[XY_set.shape[0]-1-n_last:XY_set.shape[0]-1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgZLzLqTvsmP"
      },
      "source": [
        "tring = X_test_af.iloc[0]<br>\n",
        "----------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qk4raTzQvsmP"
      },
      "source": [
        "Set up the CNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1pNAp6g8vsmP"
      },
      "outputs": [],
      "source": [
        "X = XY_set[0:XY_set.shape[0]-n_last,:cols]\n",
        "Y = XY_set[0:XY_set.shape[0]-n_last,cols:]\n",
        "input_size = X.shape[1]\n",
        "output_size = Y.shape[1]\n",
        "print(\"        Shape of input vector X =\", X.shape, '\\n')\n",
        "print(\"        Shape of output vector Y =\", Y.shape, '\\n')\n",
        "assert X.shape[0]==Y.shape[0], \"# of TEs equals # of Labels\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqY3U0JVvsmP"
      },
      "source": [
        "For reproducibility of results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GEy40I1tvsmP"
      },
      "outputs": [],
      "source": [
        "from numpy.random import seed\n",
        "seed(1)\n",
        "import tensorflow\n",
        "tensorflow.random.set_seed(2)\n",
        "from keras import backend\n",
        " \n",
        "def rmse(y_true, y_pred):\n",
        "\treturn backend.sqrt(backend.mean(backend.square(y_pred - y_true), axis=-1))\n",
        "idim = input_size\n",
        "ilayer1 = idim+3\n",
        "model = Sequential()\n",
        "model.add(Dense(ilayer1, input_dim = idim, activation = 'sigmoid'))\n",
        "model.add(Dense(int(ilayer1)+1, activation = 'sigmoid'))\n",
        "model.add(Dense(int(ilayer1)+1, activation = 'sigmoid'))\n",
        "model.add(Dense(int(ilayer1)+1, activation = 'sigmoid'))\n",
        "model.add(Dense(output_size))\n",
        "adam = Adam(lr=0.0005)\n",
        "model.compile(adam, loss = \"mse\", metrics = ['accuracy', rmse])\n",
        "print(\" Printing model summary\", model.summary(), '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pe76KpZzvsmP"
      },
      "source": [
        "Save checkpoints during training<br>\n",
        "Create a tf.keras.callbacks.ModelCheckpoint callback that saves weights only during training:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhZNPMC8vsmQ"
      },
      "source": [
        "Create a callback that saves the model's weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pu7FMHGpvsmQ"
      },
      "outputs": [],
      "source": [
        "checkpoint_path = \"NACA_training/fv.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "fv_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                            save_weights_only=True, monitor='val_loss',\n",
        "                            verbose=1, save_best_only=False)\n",
        "epochs_init = 0\n",
        "epochs_end = 10000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "su_bk7Q-vsmQ"
      },
      "source": [
        "Model #1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YSwGLJ0KvsmQ"
      },
      "outputs": [],
      "source": [
        "h = model.fit(x=X, y=Y, validation_split = 0.2, verbose =1, \n",
        "              batch_size = None, epochs = epochs_end, initial_epoch = epochs_init,\n",
        "              steps_per_epoch = 10, validation_steps = 5, \n",
        "              validation_freq=10, callbacks=[fv_callback])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hcnoe76_vsmQ"
      },
      "source": [
        "Note that validation_freq value must be less than epochs_end: otherwise get key error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHKgRz-XvsmQ"
      },
      "source": [
        "\n",
        "<br>\n",
        "#Model #2  # Errors in this case are very high<br>\n",
        "h = model.fit(x=X, y=Y, validation_split = 0.1, verbose =1, <br>\n",
        "              batch_size = None, initial_epoch =0, epochs = 10000, callbacks=[fv_callback])<br>\n",
        "<br>\n",
        "54545ls {checkpoint_dir}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ijdKe5rJvsmQ"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,4))\n",
        "plt.plot(h.history['accuracy'])\n",
        "plt.title('accuracy')\n",
        "plt.xlabel('epochs')\n",
        "plt.legend('accuracy')\n",
        "plt.figure(figsize=(12,4))\n",
        "plt.plot(h.history['rmse'])\n",
        "plt.title('rmse')\n",
        "plt.xlabel('rmse')\n",
        "plt.legend('rmse')\n",
        "plt.figure(figsize=(12,4))\n",
        "plt.plot(h.history['loss'])\n",
        "plt.plot(h.history['val_loss'])\n",
        "plt.plot(h.history['rmse'])\n",
        "plt.title('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['loss', 'val_loss', 'rmse'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YTcadDf7vsmR"
      },
      "outputs": [],
      "source": [
        "predictions = model.predict(X)\n",
        "#print(\"predicted Y =(alfa, Re, thk) =\", predictions)\n",
        "#print(\"Actual Y =(alfa, Re, thk) =\", Y)\n",
        "#print(\"Actual Y =(alfa, Re, thk) =\", Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PMFxkNbIvsmR"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "#print(\"root mean_squared_error % 5.2f\" %(mean_squared_error(Y, predictions, squared=False)/len(Y)))\n",
        "rmse = mean_squared_error(Y, predictions, squared=False)/len(Y)\n",
        "print(\"root mean_squared_error % 8.4f\" %(rmse))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtuSmG-pvsmR"
      },
      "source": [
        "----------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uh6IlorXvsmR"
      },
      "outputs": [],
      "source": [
        "XX = np.zeros((n_train, input_size))\n",
        "YY = np.zeros((n_train, input_size))\n",
        "Cp_trng = np.zeros((n_train, input_size))\n",
        "XX = X[n_beg:n_end,:]\n",
        "YY = Y[n_beg:n_end,:]\n",
        "Cp_trng = X[n_beg:n_end,0:n_Cp_var]\n",
        "Cp_trng_set = np.concatenate((x_coord, Cp_trng), axis=0)\n",
        "X_trng_par = X_par[n_beg:n_end,:]\n",
        "X_trng_af = af_trng_set[n_beg:n_end]\n",
        "X_trng_par_list = string_list_from_X_par(X_trng_par)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mae6mf_kvsmS"
      },
      "outputs": [],
      "source": [
        "print(\" \\n XX.shape \\n\" , XX.shape)\n",
        "print(\" \\n YY.shape \\n\" , YY.shape)\n",
        "print(\" \\n X_trng_par.shape \\n\" , X_trng_par.shape)\n",
        "predictions = model.predict(XX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDP0nBkWvsmS"
      },
      "outputs": [],
      "source": [
        "File_name = AF_family_name + \"_results_trng_subset_yp_\" + str(epochs_end) + \".xlsx\"\n",
        "print('\\n', \"Results on extracted training set n1:n2\", '\\n')\n",
        "print_results(predictions, YY, X_trng_par_list, X_trng_af, Cp_trng_set, File_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRieafP5vsmS"
      },
      "source": [
        "Results on unseen test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YiXx8ECuvsmS"
      },
      "outputs": [],
      "source": [
        "XX = np.zeros((X_test.shape[0],X_test.shape[1] ))\n",
        "YY = np.zeros((X_test.shape[0],X_test.shape[1] ))\n",
        "XX = X_test\n",
        "YY = Y_test\n",
        "print(\" \\n XX.shape \\n\" , XX.shape)\n",
        "print(\" \\n YY.shape \\n\" , YY.shape)\n",
        "X_test_par_list = string_list_from_X_par(X_test_par)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "znOT_FfSvsmS"
      },
      "outputs": [],
      "source": [
        "predictions = model.predict(XX)\n",
        "File_name = AF_family_name + \"_results_test_subset_yp_\" + str(epochs_end) + \".xlsx\"\n",
        "print('\\n', \"Results on unseen test set \", '\\n')\n",
        "print_results(predictions, YY, X_test_par_list, X_test_af, Cp_test_set, File_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Od6bQoJvsmS"
      },
      "outputs": [],
      "source": [
        "plot_results(predictions, YY, X_test_par_list, X_test_af, Cp_test_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4h_iYJFcvsmS"
      },
      "outputs": [],
      "source": [
        "print(\"\\n \\n exit\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "XF_AERO_Ravi9.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}