{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bruzerravi/Hello-World/blob/master/XF_AERO_Ravi11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d72XS2wZs8pD"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python\n",
        "# coding: utf-8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXRzpmePs8pF"
      },
      "source": [
        "In[73]:<br>\n",
        "Last successful run to completion on May 22, 2022"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UACbRBkqs8pG"
      },
      "source": [
        "This code works only for NACA 4 digit airfoils and output generated by Xflr5    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usyev4RBs8pG"
      },
      "source": [
        "This code is developed from Ravi9 and Ravi10 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vy_2gFNAs8pH"
      },
      "source": [
        "Ravi10 is developed from Ravi9 to have airfoil y-coordinates yp,  <br>\n",
        "Re, Alfa, camber, camber_xmax, thickness and turb parameters<br>\n",
        "(together named as fv) as input and Cp distribution as output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJfYiHv6s8pH"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Ravi9 has Cp  Re, Alfa, camber, camber_xmax, thickness and turb parameters\n",
        "# (together named as fv) as input and airfoil y-coordinates as output.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUHQgM9Ms8pH"
      },
      "source": [
        "This code is different from Ravi9 version which predicts yp coordinates given Cp distribution and flow parameters<br>\n",
        "Ravi11 predicts yp coordinates and flow parameters given Cp distribution <br>\n",
        "Both print_results and plot_results functions are implemented in this version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPz6SMq1s8pI"
      },
      "source": [
        "The code reads an output file created by XF_AERO_DataRead11 which looks like <br>\n",
        "DataSets\\\\Cp_Graph_nacaxxxx_Alfa-m6-10-1_Re-10-100-10_thk-2-12-2_turb_yp_out.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLjRreb-s8pI"
      },
      "source": [
        "The code XF_AERO_DataRead11 takes as its input the (xflr5 created)<br>\n",
        "\"DataSets\\\\Cp_Graph_nacaxxxx_Alfa-m6-10-1_Re-10-100-10_thk-2-12-2.csv\" file and outputs  <br>\n",
        "\"DataSets\\\\Cp_Graph_nacaxxxx_Alfa-m6-10-1_Re-10-100-10_thk-2-12-2_turb_yp_out.csv\"<br>\n",
        "which is the input file for this code Ravi11"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfa66e4qs8pJ"
      },
      "source": [
        "The training set is now in the proper XY form but is read as a dataframe<br>\n",
        "which must be processed to recreate the XY data for the ANN model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9JNze9Js8pJ"
      },
      "source": [
        "This version of the code checks for consistency of the training set data <br>\n",
        "read from the input file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgZMR42-s8pK"
      },
      "source": [
        "The XY dataset created from the input dataset after random shuffling is written to a .csv file<br>\n",
        "<br>\n",
        "The only input files are the *_out.csv and Profiles_nacaxxxx.csv <br>\n",
        "These are the only two inputs to run this code All other parameters are detrmined from these inputs<br>\n",
        "The number of training and test examples may be input as seen below"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiAEvdprs8pK"
      },
      "source": [
        "mport tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xm2SDI_ms8pK"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import datetime\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "#import matplotlib as mpl\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yal27p-4s8pL"
      },
      "outputs": [],
      "source": [
        "localtime = time.asctime( time.localtime(time.time()) )\n",
        "print (\"\\n \\n ***********************************Local start time :\", localtime, \"***********************************\")\n",
        "print (\"\\n \\n ******************************************** Executing XF_AERO_Ravi11 ********************************************\")\n",
        "print (\"\\n \\n *********************  Input data for this code is generated by executing XF_AERO_DataRead11 *********************\")\n",
        "print (\"\\n \\n **** XF_AERO_Ravi11 predicts profile coordinates for test cases given Cp distribution on Airfoil and the flow parameters***\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iabO1sefs8pM"
      },
      "source": [
        "File names defined"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IAhfeaN4s8pM"
      },
      "outputs": [],
      "source": [
        "data_file_in_fv = '/content/drive/MyDrive/DataSets/Cp_Graph_naca44xx_Alfa-m6-10-1_Re-10-100-10_thk-2-12-2_turb_yp_out.csv'\n",
        "data_file_af_case = data_file_in_fv[41:len(data_file_in_fv)-8]\n",
        "data_file_out_yp = data_file_af_case +\"_out.xlsx\"\n",
        "data_file_in_Pr = '/content/drive/MyDrive/DataSets/Profiles_naca44xx.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nIUY81ixs8pM"
      },
      "outputs": [],
      "source": [
        "AF_family_name = data_file_in_fv[41:49]\n",
        "n_test = 10\n",
        "n_train = 10\n",
        "n_beg = 101              # Select the training examples starting from n_beg\n",
        "n_end = n_beg + n_train\n",
        "print (\"\\n \\n ** The Input data file for this run is\",data_file_in_fv, \"**\")\n",
        "#-----------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rwiq4GOs8pM"
      },
      "source": [
        "----------------------------------------------------------------------------<br>\n",
        "The calling function is<br>\n",
        "print_results(predictions, YY, X_trng_par_list, X_trng_af, Cp_trng_set, File_name)<br>\n",
        "Function definition to print results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qChfrs40s8pM"
      },
      "source": [
        "Consolidate the reults matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-DeD9k-s8pN"
      },
      "source": [
        "Write the results Dataset to an .xlsx file<br>\n",
        "   print(\"results.shape is\", results.shape)<br>\n",
        "   print(\"row labels =\", row_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DmfBSAtis8pM"
      },
      "outputs": [],
      "source": [
        "def print_results(Y_p, Y_a, X_par_list, X_af, Cp_set, file_name):\n",
        "    \n",
        "    np.set_printoptions(precision=3)\n",
        "    \n",
        "    file_name = \"Ravi11_\" + file_name    \n",
        "    print(\" \\n Y_p.shape \\n\" , Y_p.shape)\n",
        "    print(\" \\n Y_a.shape \\n\" , Y_a.shape)\n",
        "    print(\" \\n Cp_set.shape \\n\" , Cp_set.shape)\n",
        "    results = np.zeros((1,Y_a.shape[1]))\n",
        "    results[0,:] = Cp_set[0,:]\n",
        "    results = np.concatenate((results, Y_a), axis=0)\n",
        "    results = np.concatenate((results, Y_p), axis=0)\n",
        "    results = np.concatenate((results, Cp_set[1:,:]), axis=0)    \n",
        "    length_Xaf = len(X_af)\n",
        "# Collect Alfa, Re, thk results in an array to be written out in a file\n",
        "    length_Xpar = int(len(X_par_list)/2)         #divide by 2 because the length of X_par_list is double of X_af\n",
        "    row_labels = []\n",
        "    row_labels.append('x_p')\n",
        "    index = np.arange(0,len(X_par_list),1)\n",
        "    for i in index:\n",
        "        stringi = X_par_list[i]\n",
        "        row_labels.append(X_par_list[i])\n",
        "   \n",
        "    \n",
        "    index = np.arange(1,length_Xaf+1,1)\n",
        "    for i in index:\n",
        "        string_af = X_af[i-1]\n",
        "        row_labels[i] = string_af + '-' + row_labels[i]\n",
        "    index = np.arange(1,length_Xaf+1,1)\n",
        "    for i in index:\n",
        "        string_af = X_af[i-1]\n",
        "        row_labels[length_Xaf+i] = string_af + row_labels[length_Xaf+i]\n",
        "    len(row_labels)\n",
        "    index = np.arange(0,length_Xpar,1)\n",
        "    for i in index:\n",
        "        stringi = X_par_list[i]\n",
        "        string1 = stringi[0:61] + 'Cp' + stringi[63:]\n",
        "        row_labels.append(string1)\n",
        "    index = np.arange(1,length_Xaf+1,1)\n",
        "    for i in index:\n",
        "        string_af = X_af[i-1]\n",
        "        row_labels[2*length_Xpar+i] = string_af + row_labels[2*length_Xpar+i]\n",
        "    df_results = pd.DataFrame(data=results, index=row_labels)\n",
        "    df_results.to_excel(file_name)\n",
        "    return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPHalxA-s8pO"
      },
      "source": [
        "Function definition to plot results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILpbFKWps8pO"
      },
      "source": [
        "Calling function and arguments<br>\n",
        "lot_results(predictions, YY, X_test_par_list, X_test_af, Cp_test_set)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ML45MNuFs8pO"
      },
      "source": [
        "Consolidate the results matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAr24Ldzs8pO"
      },
      "source": [
        "Create a dataframe of the results that can be plotted as graphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wJ7HizSYs8pO"
      },
      "outputs": [],
      "source": [
        "def plot_results(Y_p, Y_a, X_par_list, X_af, Cp_set):\n",
        "    \n",
        "    length_Xaf = len(X_af)\n",
        "    Y_size = Y_p.shape\n",
        "    results = np.zeros((1,Y_a.shape[1]))\n",
        "    results[0,:] = Cp_set[0,:]                                  # sets the x-coordinates\n",
        "    results = np.concatenate((results, Cp_set[1:,:]), axis=0)   # the Cp distribution of the profile    \n",
        "    results = np.concatenate((results, Y_a), axis=0)            # Actual yp distribution\n",
        "    results = np.concatenate((results, Y_p), axis=0)            # predicted yp distribution\n",
        "    df_results = pd.DataFrame(data=results)\n",
        "    yp_err = np.zeros((1,Y_size[1]))\n",
        "    i_count = 0                         # count of number of test airfoils\n",
        "    while (i_count <= Y_size[0]-1):\n",
        "        row_labels = [\"Airfoil Cp Distribution\", \"yp_Actual\", \"yp_pred\", \"yp_err\"]\n",
        "        yp_err = np.array(df_results.iloc[Y_size[0] + i_count+1, :]-df_results.iloc[2*Y_size[0] + i_count+1, :])\n",
        "        Title1 = X_par_list[i_count]\n",
        "        Title2 = X_af[i_count] + \"_\" + Title1[0:53] + Title1[64:]\n",
        "        plt.figure(figsize=(15,7))\n",
        "        plt.plot(df_results.iloc[0, :], df_results.iloc[i_count+1, :])\n",
        "        plt.plot(df_results.iloc[0, :], df_results.iloc[Y_size[0] + i_count+1, :], marker='+')\n",
        "        plt.plot(df_results.iloc[0, :], df_results.iloc[2*Y_size[0] + i_count+1, :], marker='*')\n",
        "        plt.plot(df_results.iloc[0, :], yp_err[:], marker = 'o')\n",
        "        tit = Title2 + \" : Airfoil Cp Distribution and Profile\" \n",
        "        plt.title(tit)\n",
        "        plt.xlabel('x')\n",
        "        plt.ylabel('y, Cp')\n",
        "        plt.legend(row_labels, loc=1, prop={'size': 8})\n",
        "        i_count += 1\n",
        "    \n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_2rhkyCMs8pP"
      },
      "outputs": [],
      "source": [
        "def string_list_from_X_par(X_par_list):\n",
        "# Generate string list from X_par_list\n",
        "# Merge all entries in array column to a string\n",
        "    jrange = X_par_list.shape[1]\n",
        "    irange = X_par_list.shape[0]\n",
        "    si = []\n",
        "    i=0\n",
        "    while (i<= irange-1):\n",
        "        j=0\n",
        "        sj = \" \"\n",
        "        while (j<= jrange-1):\n",
        "            if j< jrange-1:\n",
        "                sj =  sj  + str(X_par_list[i,j]) + \" , \"\n",
        "            else:\n",
        "                sj =  sj  + str(X_par_list[i,j])\n",
        "            j = j+1\n",
        "        si.append(sj)\n",
        "        i = i+1\n",
        "    \n",
        "    i=0\n",
        "    while (i<= irange-1):\n",
        "        si[i] = \"(Alfa , Re, cmbr, cmbrx, thk,  NCrit, XTrTop, XtrBot)-actual-yp =\" + si[i]\n",
        "        i +=1\n",
        "    \n",
        "    i = irange\n",
        "    k=0\n",
        "    while (i<= 2*irange-1):\n",
        "        string = si[k]\n",
        "        sj = \"(Alfa , Re, cmbr, cmbrx, thk, NCrit, XTrTop, XtrBot)-pred-yp =\" + string[65:]\n",
        "        si.append(sj)\n",
        "        i +=1\n",
        "        k +=1\n",
        "    return si"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B613ouu6s8pP"
      },
      "source": [
        "Read the input data frame consisting of the training set<br>\n",
        "Note that each row of the input dataframe has n_Cp_var (=99) values followed by <br>\n",
        "n_par_var (=8) parameter variables and then n_yp_var (=99=n_yp_var) coordinate values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fvIT-nfks8pP"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(data_file_in_fv)\n",
        "df = df.sample(frac=1)\n",
        "df_Pr = pd.read_csv(data_file_in_Pr)\n",
        "af_trng_set = []\n",
        "af_trng_set = list(df.iloc[:,0])                # Extract airfoil names from column 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ve_6xL4Fs8pP"
      },
      "source": [
        "delete the first column from the dataframe read since that is only the row serial #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hX1fiNA8s8pP"
      },
      "outputs": [],
      "source": [
        "df = df.iloc[:,1:]\n",
        "df_size = df.shape\n",
        "af_family = data_file_af_case[0:8] \n",
        "dfPr_size = df_Pr.shape\n",
        "n_Cp_var=dfPr_size[0]\n",
        "n_yp_var = n_Cp_var"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a50FipNos8pP"
      },
      "source": [
        "save the x-y set for each profile.  Note that the x-coordinate is same for all profiles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DwkmG8aks8pP"
      },
      "outputs": [],
      "source": [
        "n_profiles = int(dfPr_size[1]/2)\n",
        "x_y_prof_coords = np.zeros((n_yp_var, n_profiles+1))\n",
        "x_y_prof_coords[:,0:2] = df_Pr.iloc[:,0:2]\n",
        "i = 3\n",
        "j = 2\n",
        "while (i <= 2*n_profiles-1):\n",
        "    x_y_prof_coords[:,j] = df_Pr.iloc[:,i]\n",
        "    i +=2\n",
        "    j +=1\n",
        "x_y_prof_coords = np.transpose(x_y_prof_coords)\n",
        "x_coord = np.zeros((1,n_yp_var))\n",
        "x_coord[0,:] = x_y_prof_coords[0,:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UiBxomzs8pQ"
      },
      "source": [
        "denote feature variable by fv_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMn9f4-ds8pQ"
      },
      "source": [
        "Store the parameter array for later use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lazJS1J1s8pQ"
      },
      "outputs": [],
      "source": [
        "n_in_var = n_Cp_var                     # the input is the Cp distribution\n",
        "n_out_var = df_size[1] - n_in_var       # the output variables here are yp coordinates plus flow variables (8)\n",
        "n_par_var = n_out_var - n_in_var        # this is the number of flow variables\n",
        "fv_last = n_in_var-1        # Note that this is the column index of last fv value in any row\n",
        "col_last = df_size[1]-1     # Note that this is the column index of last value in any row"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRgwefR3s8pQ"
      },
      "outputs": [],
      "source": [
        "print('\\n', \"          Feature variables are the upper and lower surface fv data - just Cp distribution in this code \\n\")\n",
        "print('\\n', \"          Output variables are the upper and lower surface coordinate data, Alfa , Re, cmbr, cmbrx, thk, NCrit, XTrTop, XtrBot \\n\")\n",
        "print(\"           size of Training Set is \", df_size[0], '\\n \\n')\n",
        "print(\"           length of dataframe is \", df_size[1], '\\n \\n')\n",
        "print(\"           size of fv_data is \", df_size[1]-n_out_var, '\\n \\n')\n",
        "print(\"           the fv value in row #0 col #0 is  df.iloc[0,0] =\", df.iloc[0,0], '\\n \\n')\n",
        "print(\"           the last fv value in row #0 col #last is  df.iloc[0,last] =\", df.iloc[0,fv_last], '\\n \\n')\n",
        "print(\"           the last non-zero element on df.iloc[0,df_size[1]-1] =\", df.iloc[0,col_last], '\\n \\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8MmQ_Anks8pQ"
      },
      "outputs": [],
      "source": [
        "fv_data = np.array(df.iloc[:,0:fv_last+1])\n",
        "X_par =  np.array(df.iloc[:,n_Cp_var:n_Cp_var+n_par_var])\n",
        "print(\"            The 8 values in any row of X_par are the flow parameters ALfa, Re etc\")\n",
        "print(\"           X_par[0,*]\", X_par[0, 0:9])\n",
        "print('\\n', \"           number of sets of fv_data is \", len(fv_data), '\\n')\n",
        "print(\"           the last fv value in row #0 col #last is  fv_data[0,last] =\", fv_data[0,fv_last], '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arwx0bcNs8pR"
      },
      "source": [
        "reate X data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AwpyvF3Cs8pR"
      },
      "outputs": [],
      "source": [
        "X = fv_data\n",
        "X = X.astype(float)\n",
        "n_fv_data = X.shape[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-sHo11Ts8pR"
      },
      "source": [
        "reating Y data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eGAY4Dtms8pR"
      },
      "outputs": [],
      "source": [
        "Y = []\n",
        "Y = np.array(df.iloc[:,fv_last+1:])\n",
        "print(\"            The first 8 values in any row of Y are the flow parameters ALfa, Re etc\")\n",
        "print(\"            Y[0,*]\", Y[0, 0:8])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VohgHP2rs8pR"
      },
      "source": [
        " = Y.astype(float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2A0-L5i0s8pR"
      },
      "outputs": [],
      "source": [
        "print(\"  \\n \\n    the last non-zero element on Y[0,row_last] =\", Y[0,n_out_var-1], '\\n')\n",
        "print(\"Last values in Y of row #0 \\n \\n y-coordinates \\n \\n\", Y[0, 0:])\n",
        "print(\" \\n \\n The first 8 data in every row of Y are respectively \")\n",
        "print(\" Alfa_in_Deg, Re*10000, 10*cmbr%, cmbrx%, thk%, NCrit, XTrtop, XTrbot \\n\")\n",
        "print(\" \\n Y \\n\" , Y[0, 0:8])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4oTehx9s8pS"
      },
      "source": [
        "Create XY set and shuffle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yID8C_S2s8pS"
      },
      "outputs": [],
      "source": [
        "rows = X.shape[0]\n",
        "cols = X.shape[1]\n",
        "print('\\n', \"           rows =\", rows, \"cols =\", cols, '\\n')\n",
        "assert fv_data.shape[0]==Y.shape[0], \"# of fv sets equals # of test Labels\"\n",
        "XY_set = np.zeros((rows,cols))\n",
        "print(\" \\n  XY set initialized       \\n\", XY_set.shape)\n",
        "XY_set = X\n",
        "print(\"    \\n XY set only feature variables \\n      \", XY_set.shape)\n",
        "XY_set = np.hstack((XY_set, Y))\n",
        "print(\"   \\n XY set Feature and Output variable \\n  \\n     \", XY_set.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SEKCH8is8pS"
      },
      "source": [
        "Shuffle the training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0UE7Z7Dos8pS"
      },
      "outputs": [],
      "source": [
        "np.random.shuffle(XY_set)\n",
        "print(\"\\n     XY_set after random shuffle  \\n \", XY_set.shape, '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJtcgwbys8pS"
      },
      "source": [
        "ake the n_last  examples as the test set<br>\n",
        "Note that in this case the number of columns for X is n_in_var and <br>\n",
        "the number of columns for Y is n_out_var (=n_in_var + n_par_var)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TFag75BUs8pT"
      },
      "outputs": [],
      "source": [
        "X_test = np.zeros((n_test,cols))\n",
        "Y_test = np.zeros((n_test,cols))\n",
        "Cp_test = np.zeros((n_test,cols))\n",
        "n_last = n_test\n",
        "X_test = XY_set[XY_set.shape[0]-1-n_last:XY_set.shape[0]-1,:cols]\n",
        "Y_test = XY_set[XY_set.shape[0]-1-n_last:XY_set.shape[0]-1,cols:]\n",
        "assert X_test.shape[0]==Y_test.shape[0], \"# of test exampless equals # of test Labels\"\n",
        "Cp_test = XY_set[XY_set.shape[0]-1-n_last:XY_set.shape[0]-1,0:n_Cp_var]\n",
        "Cp_test_set = np.concatenate((x_coord, Cp_test), axis=0)\n",
        "X_test_par = XY_set[XY_set.shape[0]-1-n_last:XY_set.shape[0]-1,n_Cp_var:n_Cp_var+n_par_var]\n",
        "X_test_af = af_trng_set[XY_set.shape[0]-1-n_last:XY_set.shape[0]-1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjyKqC_rs8pT"
      },
      "source": [
        "Set up the ANN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "piLusmuts8pT"
      },
      "outputs": [],
      "source": [
        "X = XY_set[0:XY_set.shape[0]-n_last,:cols]\n",
        "Y = XY_set[0:XY_set.shape[0]-n_last,cols:]\n",
        "input_size = X.shape[1]\n",
        "output_size = Y.shape[1]\n",
        "print(\"        Shape of input vector X =\", X.shape, '\\n')\n",
        "print(\"        Shape of output vector Y =\", Y.shape, '\\n')\n",
        "assert X.shape[0]==Y.shape[0], \"# of TEs equals # of Labels\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J00xuxvss8pT"
      },
      "source": [
        "For reproducibility of results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gad-3EORs8pT"
      },
      "outputs": [],
      "source": [
        "from numpy.random import seed\n",
        "seed(1)\n",
        "import tensorflow\n",
        "tensorflow.random.set_seed(2)\n",
        "from keras import backend\n",
        " \n",
        "def rmse(y_true, y_pred):\n",
        "\treturn backend.sqrt(backend.mean(backend.square(y_pred - y_true), axis=-1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UVAsJznms8pU"
      },
      "outputs": [],
      "source": [
        "idim = input_size\n",
        "ilayer1 = idim+3\n",
        "model = Sequential()\n",
        "model.add(Dense(ilayer1, input_dim = idim, activation = 'sigmoid'))\n",
        "model.add(Dense(int(ilayer1)+1, activation = 'sigmoid'))\n",
        "model.add(Dense(int(ilayer1)+1, activation = 'sigmoid'))\n",
        "model.add(Dense(int(ilayer1)+1, activation = 'sigmoid'))\n",
        "model.add(Dense(output_size))\n",
        "adam = Adam(lr=0.0005)\n",
        "model.compile(adam, loss = \"mse\", metrics = ['accuracy', rmse])\n",
        "print(\" Printing model summary\", model.summary(), '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyMN91OXs8pU"
      },
      "source": [
        "Save checkpoints during training<br>\n",
        "Create a tf.keras.callbacks.ModelCheckpoint callback that saves weights only during training:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imupiKg7s8pU"
      },
      "outputs": [],
      "source": [
        "checkpoint_path = \"NACA_training/fv.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_4pNFNqs8pU"
      },
      "source": [
        "Create a callback that saves the model's weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jbqsu1fZs8pU"
      },
      "outputs": [],
      "source": [
        "fv_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                            save_weights_only=True, monitor='val_loss',\n",
        "                            verbose=1, save_best_only=False)\n",
        "epochs_init = 0\n",
        "epochs_end = 10000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tmBP75Us8pU"
      },
      "source": [
        "Model #1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WVcXRUQ_s8pU"
      },
      "outputs": [],
      "source": [
        "h = model.fit(x=X, y=Y, validation_split = 0.2, verbose =1, \n",
        "              batch_size = None, epochs = epochs_end, initial_epoch = epochs_init,\n",
        "              steps_per_epoch = 10, validation_steps = 5, \n",
        "              validation_freq=10, callbacks=[fv_callback])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqOqnJhbs8pU"
      },
      "source": [
        "Note that validation_freq value must be less than epochs_end: otherwise get key error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZeb1AFFs8pU"
      },
      "source": [
        "\n",
        "<br>\n",
        "#Model #2  # Errors in this case are very high<br>\n",
        "h = model.fit(x=X, y=Y, validation_split = 0.1, verbose =1, <br>\n",
        "              batch_size = None, initial_epoch =0, epochs = 10000, callbacks=[fv_callback])<br>\n",
        "<br>\n",
        "54545ls {checkpoint_dir}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nkAGaXbps8pV"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,4))\n",
        "plt.plot(h.history['accuracy'])\n",
        "plt.title('accuracy')\n",
        "plt.xlabel('epochs')\n",
        "plt.legend('accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oAAa0foOs8pV"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,4))\n",
        "plt.plot(h.history['rmse'])\n",
        "plt.title('rmse')\n",
        "plt.xlabel('rmse')\n",
        "plt.legend('rmse')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4xN0Etr4s8pV"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,4))\n",
        "plt.plot(h.history['loss'])\n",
        "plt.plot(h.history['val_loss'])\n",
        "plt.plot(h.history['rmse'])\n",
        "plt.title('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['loss', 'val_loss', 'rmse'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "35IRkdsNs8pV"
      },
      "outputs": [],
      "source": [
        "predictions = model.predict(X)\n",
        "print(\"predicted Y =(alfa, Re, thk) =\", predictions)\n",
        "print(\"Actual Y =(alfa, Re, thk) =\", Y)\n",
        "print(\"Actual Y =(alfa, Re, thk) =\", Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VOM1v9n_s8pV"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "print(\"root mean_squared_error % 5.2f\" %(mean_squared_error(Y, predictions, squared=False)/len(Y)))\n",
        "rmse = mean_squared_error(Y, predictions, squared=False)/len(Y)\n",
        "print(\"root mean_squared_error % 8.4f\" %(rmse))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ul-d9Rr6s8pV"
      },
      "outputs": [],
      "source": [
        "XX = np.zeros((n_train, input_size))\n",
        "YY = np.zeros((n_train, output_size))\n",
        "Cp_trng = np.zeros((n_train, input_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aiS0sexMs8pV"
      },
      "outputs": [],
      "source": [
        "XX = X[n_beg:n_end,:]\n",
        "YY = Y[n_beg:n_end,:]\n",
        "X_par_trng = Y[n_beg:n_end, 0:n_par_var]\n",
        "Cp_trng = X[n_beg:n_end,0:n_Cp_var]\n",
        "Cp_trng_set = np.concatenate((X_par_trng, Cp_trng), axis=1)\n",
        "x_coord_zeroes = np.zeros((1,8))\n",
        "x_coord = np.concatenate((x_coord_zeroes, x_coord), axis=1)\n",
        "Cp_trng_set = np.concatenate((x_coord, Cp_trng_set), axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n9RlEOffs8pV"
      },
      "outputs": [],
      "source": [
        "X_par =  np.array(df.iloc[:,n_Cp_var:n_Cp_var+n_par_var])\n",
        "X_trng_par = X_par[n_beg:n_end,:]\n",
        "X_trng_af = af_trng_set[n_beg:n_end]\n",
        "X_trng_par_list = string_list_from_X_par(X_trng_par)\n",
        "predictions = model.predict(XX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ugGSs2T_s8pW"
      },
      "outputs": [],
      "source": [
        "print(\" \\n XX.shape \\n\" , XX.shape)\n",
        "print(\" \\n YY.shape \\n\" , YY.shape)\n",
        "print(\" \\n X_trng_par.shape \\n\" , X_trng_par.shape)\n",
        "print(\" \\n predictions.shape \\n\" , predictions.shape)\n",
        "print(\" \\n Cp_trng_set.shape \\n\" , Cp_trng_set.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l0Utk1kXs8pW"
      },
      "outputs": [],
      "source": [
        "print(\" \\n X_trng_par \\n\" , X_trng_par)\n",
        "print(\" \\n X_trng_af \\n\" , X_trng_af)\n",
        "print(\" \\n X_trng_par_list \\n\" , X_trng_par_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1tswG9khs8pW"
      },
      "outputs": [],
      "source": [
        "print(\" \\n \\n The first 8 data in every row of Y are respectively \")\n",
        "print(\" Alfa_in_Deg, Re*10000, 10*cmbr%, cmbrx%, thk%, NCrit, XTrtop, XTrbot \\n\")\n",
        "print(\" \\n YY \\n\" , Y[0, 0:8])\n",
        "print(\" \\n predictions \\n\" , predictions[0, 0:8])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dGViHizxs8pW"
      },
      "outputs": [],
      "source": [
        "File_name = AF_family_name + \"_results_trng_subset_yp_\" + str(epochs_end) + \".xlsx\"\n",
        "print('\\n', \"Results on extracted training set n1:n2\", '\\n')\n",
        "print_results(predictions, YY, X_trng_par_list, X_trng_af, Cp_trng_set, File_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epAnsFkus8pW"
      },
      "source": [
        "Results on unseen test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BcZeg5ENs8pW"
      },
      "outputs": [],
      "source": [
        "XX = np.zeros((X_test.shape[0],X_test.shape[1] ))\n",
        "YY = np.zeros((X_test.shape[0],X_test.shape[1] ))\n",
        "XX = X_test\n",
        "YY = Y_test\n",
        "X_test_par_list = string_list_from_X_par(X_test_par)\n",
        "Cp_test_set = np.concatenate((X_test_par, Cp_test), axis=1)\n",
        "Cp_test_set = np.concatenate((x_coord, Cp_test_set), axis=0)\n",
        "predictions = model.predict(XX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FAqsXl6Hs8pX"
      },
      "outputs": [],
      "source": [
        "print(\" \\n XX.shape \\n\" , XX.shape)\n",
        "print(\" \\n YY.shape \\n\" , YY.shape)\n",
        "print(\" \\n predictions.shape \\n\" , predictions.shape)\n",
        "print(\" \\n Cp_test_set.shape \\n\" , Cp_test_set.shape)\n",
        "#print(\" \\n X_test_par_list \\n\" , X_test_par_list)\n",
        "#print(\" \\n X_test_af \\n\" , X_test_af)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2B0MHhTls8pX"
      },
      "outputs": [],
      "source": [
        "File_name = AF_family_name + \"_results_test_subset_yp_\" + str(epochs_end) + \".xlsx\"\n",
        "print('\\n', \"Results on unseen test set \", '\\n')\n",
        "print_results(predictions, YY, X_test_par_list, X_test_af, Cp_test_set, File_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PILJV5qjs8pX"
      },
      "outputs": [],
      "source": [
        "plot_results(predictions, YY, X_test_par_list, X_test_af, Cp_test_set)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7IS_qfJCs8pX"
      },
      "source": [
        "---------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fz3L-e3As8pX"
      },
      "outputs": [],
      "source": [
        "print(\"\\n \\n exit XF_AERO_Ravi11 \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l1zfQ7bKs8pX"
      },
      "outputs": [],
      "source": [
        "print(\"*****************************************************************************\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iy2DkdMhs8pX"
      },
      "source": [
        "****************************************************************************"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "XF_AERO_Ravi11.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}